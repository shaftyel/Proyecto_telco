# üìä TelcoVision - Sistema MLOps para Predicci√≥n de Churn

**Trabajo Pr√°ctico Integrador - Laboratorio de Miner√≠a de Datos**

Sistema completo de Machine Learning con versionado de datos, tracking de experimentos y despliegue colaborativo para predecir la cancelaci√≥n de servicios (churn) en clientes de telecomunicaciones.

---

## üë• Equipo

- **Estudiantes:** 
				Evelyn Solange Irusta / 
				Ignacio Heck
- **Instituci√≥n:** ISTEA
- **Materia:** Laboratorio de Miner√≠a de Datos
- **Fecha:** Octubre 2025

---

## üéØ Objetivo

Implementar un pipeline end-to-end de Machine Learning con:
- Versionado de datos y modelos (DVC)
- Tracking de experimentos (MLflow)
- Colaboraci√≥n remota (DagsHub)
- Reproducibilidad total del proyecto

---

## üìÅ Estructura del Proyecto

```
Proyecto_Laboratorio_MineriaV2/
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îú‚îÄ‚îÄ raw/                           # Dataset original (10,000 registros)
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ telco_churn.csv           # Versionado con DVC
‚îÇ   ‚îî‚îÄ‚îÄ processed/                     # Dataset limpio
‚îÇ       ‚îî‚îÄ‚îÄ telco_churn_processed.csv # Versionado con DVC
‚îú‚îÄ‚îÄ models/
‚îÇ   ‚îú‚îÄ‚îÄ model.joblib                  # Modelo entrenado (RandomForest)
‚îÇ   ‚îî‚îÄ‚îÄ metrics.json                  # M√©tricas de evaluaci√≥n
‚îú‚îÄ‚îÄ params_experiments/               # 5 configuraciones de experimentos
‚îÇ   ‚îú‚îÄ‚îÄ exp1_rf_baseline.yaml
‚îÇ   ‚îú‚îÄ‚îÄ exp2_rf_optimized.yaml
‚îÇ   ‚îú‚îÄ‚îÄ exp3_rf_regularized.yaml
‚îÇ   ‚îú‚îÄ‚îÄ exp4_logistic_baseline.yaml
‚îÇ   ‚îî‚îÄ‚îÄ exp5_logistic_l1.yaml
‚îú‚îÄ‚îÄ reports/
‚îÇ   ‚îú‚îÄ‚îÄ experiments_comparison.csv    # Comparaci√≥n de todos los experimentos
‚îÇ   ‚îî‚îÄ‚îÄ experiments_comparison.json
‚îú‚îÄ‚îÄ scripts/
‚îÇ   ‚îú‚îÄ‚îÄ run_experiments.py           # Ejecutor de m√∫ltiples experimentos
‚îÇ   ‚îî‚îÄ‚îÄ register_best_model.py       # Registro en Model Registry
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ data_prep.py                 # Limpieza y transformaci√≥n de datos
‚îÇ   ‚îî‚îÄ‚îÄ train.py                      # Entrenamiento con MLflow
‚îú‚îÄ‚îÄ .dvc/                             # Configuraci√≥n DVC
‚îú‚îÄ‚îÄ mlruns/                           # Experimentos MLflow (local)
‚îú‚îÄ‚îÄ params.yaml                       # Configuraci√≥n principal del modelo
‚îú‚îÄ‚îÄ requirements.txt                  # Dependencias del proyecto
‚îî‚îÄ‚îÄ README.md                         # Este archivo
```

---

## üîß Tecnolog√≠as Utilizadas

| Herramienta | Prop√≥sito | Versi√≥n |
|-------------|-----------|---------|
| **Python** | Lenguaje principal | 3.9+ |
| **scikit-learn** | Modelos ML | 1.3.0 |
| **pandas** | Manipulaci√≥n de datos | 2.0.3 |
| **MLflow** | Tracking de experimentos | 2.15.0 |
| **DVC** | Versionado de datos/modelos | 3.50.0 |
| **DagsHub** | Colaboraci√≥n y hosting remoto | - |
| **Git** | Control de versiones | 2.x |

---

## üìä Dataset

### Caracter√≠sticas
- **Nombre:** Telco Customer Churn Dataset
- **Registros:** 10,000 clientes
- **Features:** 24 (despu√©s de one-hot encoding)
  - **Originales:** 12 features (9 categ√≥ricas, 3 num√©ricas)
  - **Procesadas:** 24 features binarias/num√©ricas
- **Variable objetivo:** `churn` (0: Cliente activo, 1: Cliente cancel√≥)
- **Distribuci√≥n de clases:**
  - No churn (0): 6,367 (63.67%)
  - Churn (1): 3,633 (36.33%)

### Variables Principales
- `tenure_months`: Meses de antig√ºedad del cliente
- `monthly_charges`: Cargo mensual
- `total_charges`: Cargos totales acumulados
- Features categ√≥ricas: tipo de contrato, servicios contratados, m√©todo de pago, etc.

### Preprocesamiento Realizado
1. Normalizaci√≥n de nombres de columnas
2. Conversi√≥n de `total_charges` a num√©rico
3. Imputaci√≥n de valores faltantes (mediana)
4. Eliminaci√≥n de identificadores de cliente
5. One-hot encoding de variables categ√≥ricas (drop_first=True)
6. Estandarizaci√≥n de features num√©ricas (StandardScaler)

---

## ü§ñ Modelos Implementados

### Modelo Principal: Random Forest
```yaml
Configuraci√≥n:
  n_estimators: 300
  max_depth: null (sin l√≠mite)
  min_samples_split: 2
  min_samples_leaf: 1
  class_weight: balanced_subsample
  random_state: 42
```

### Experimentos Adicionales
1. **RandomForest Baseline** - Configuraci√≥n conservadora (100 √°rboles, max_depth=10)
2. **RandomForest Optimized** - Configuraci√≥n agresiva (500 √°rboles, sin l√≠mite de profundidad)
3. **RandomForest Regularized** - Con regularizaci√≥n (max_depth=8, min_samples_split=10)
4. **Logistic Regression L2** - Baseline con regularizaci√≥n Ridge
5. **Logistic Regression L1** - Con regularizaci√≥n Lasso

---

## üìà Resultados

### M√©tricas del Modelo Principal (RandomForest)
```
Accuracy:    66.35%
Precision:   55.38%
Recall:      38.24%
F1-Score:    45.24%
ROC-AUC:     69.89%
```

**Interpretaci√≥n:**
- El modelo tiene un desempe√±o moderado en la predicci√≥n de churn
- Alta especificidad (bajo falsos positivos)
- Recall mejorable - algunos casos de churn no son detectados
- ROC-AUC cercano a 0.70 indica capacidad discriminativa aceptable

### Comparaci√≥n de Experimentos
Ver archivo completo en: `reports/experiments_comparison.csv`

| Experimento | Modelo | Accuracy | Precision | Recall | F1-Score | ROC-AUC | Caracter√≠sticas |
|-------------|--------|----------|-----------|--------|----------|---------|-----------------|
| **Logistic L2** | Logistic Regression | **65.55%** | 51.92% | **70.56%** | 59.83% | **72.66%** | Regularizaci√≥n Ridge (L2), mejor ROC-AUC |
| Logistic L1 | Logistic Regression | 65.50% | 51.85% | 71.39% | 60.07% | 72.63% | Regularizaci√≥n Lasso (L1) |
| RF Regularized | Random Forest | 66.40% | 53.24% | 62.17% | 57.36% | 71.99% | Max_depth=8, min_samples_split=10 |
| RF Baseline | Random Forest | 65.90% | 52.51% | 64.65% | 57.95% | 72.15% | Conservador, 100 √°rboles, max_depth=10 |
| RF Optimized | Random Forest | 66.35% | **55.38%** | 38.24% | 45.24% | 69.89% | Agresivo, 500 √°rboles, sin l√≠mite profundidad |


### Comparaci√≥n Visual
```
ROC-AUC (cuanto m√°s alto, mejor):
Logistic L2     ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà 72.66%
Logistic L1     ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà 72.63%
RF Baseline     ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  72.15%
RF Regularized  ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  71.99%
RF Optimized    ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà       69.89%

F1-Score (balance precision-recall):
Logistic L1     ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà 60.07%
Logistic L2     ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  59.83%
RF Baseline     ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà          57.95%
RF Regularized  ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà           57.36%
RF Optimized    ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                       45.24%
```
---

## üî¨ Implementaci√≥n MLOps

### 1. Versionado de Datos (DVC)
- Dataset raw versionado: `data/raw/telco_churn.csv.dvc`
- Dataset procesado versionado: `data/processed/telco_churn_processed.csv.dvc`
- Modelo versionado: `models/model.joblib.dvc`
- **Ventaja:** Trazabilidad completa de cambios en datos y modelos

### 2. Tracking de Experimentos (MLflow)
- **Experimento:** `proyecto_telco`
- **Tracking remoto:** DagsHub
- **M√©tricas registradas:** accuracy, precision, recall, f1, roc_auc
- **Par√°metros registrados:** tipo de modelo, hiperpar√°metros, config de split
- **Artifacts:** Modelo .joblib, m√©tricas .json

### 3. Reproducibilidad
- **params.yaml:** Configuraci√≥n centralizada
- **requirements.txt:** Dependencias fijadas
- **Scripts automatizados:** Entrenamiento y experimentaci√≥n reproducibles
- **DVC pipelines:** Pipeline de preprocesamiento y entrenamiento

### 4. Colaboraci√≥n (DagsHub)
- **Repositorio:** https://dagshub.com/Nacho/Proyecto_Telco
- **Caracter√≠sticas:**
  - C√≥digo versionado (Git)
  - Datos versionados (DVC)
  - Experimentos visualizables (MLflow)
  - Colaboraci√≥n habilitada

---

## üöÄ Ejecuci√≥n del Proyecto

### Instalaci√≥n
```bash
# Clonar repositorio
git clone https://dagshub.com/Nacho/Proyecto_Telco.git
cd Proyecto_Laboratorio_Mineria

# Crear entorno virtual
conda create -n proyecto_mineria python=3.9 -y
conda activate proyecto_mineria

# Instalar dependencias
pip install -r requirements.txt

# Descargar datos (DVC)
dvc pull
```

### Entrenar Modelo
```bash
# Entrenamiento con configuraci√≥n por defecto
python src/train.py --params params.yaml

# Ver experimentos en MLflow
mlflow ui --port 5000
# Abrir: http://localhost:5000
```

### Ejecutar Todos los Experimentos
```bash
# Ejecutar los 5 experimentos configurados
python scripts/run_experiments.py

# Registrar mejor modelo en Model Registry
python scripts/register_best_model.py \
  --experiment proyecto_telco \
  --metric roc_auc \
  --model-name TelcoChurn_Model
```

---

## üìä An√°lisis y Conclusiones

### Hallazgos Principales
1. **Desbalance de clases:** El dataset tiene 36% de churn, lo cual requiere t√©cnicas de balanceo
2. **Features importantes:** `tenure_months`, `monthly_charges` y `total_charges` son predictores clave
3. **Trade-off precision-recall:** El modelo prioriza precisi√≥n sobre recall
4. **Mejoras posibles:** 
   - Balanceo de clases (SMOTE, undersampling)
   - Feature engineering adicional
   - Ensambles de modelos

### Ventajas del Enfoque MLOps
- ‚úÖ **Reproducibilidad total:** Cualquier experimento puede replicarse
- ‚úÖ **Trazabilidad:** Hist√≥rico completo de cambios en datos y modelos
- ‚úÖ **Colaboraci√≥n:** F√°cil compartir resultados con el equipo
- ‚úÖ **Experimentaci√≥n r√°pida:** Framework para probar m√∫ltiples configuraciones
- ‚úÖ **Versionado inteligente:** Solo se almacenan diferencias, no archivos completos

### Lecciones Aprendidas
1. La importancia del versionado de datos, no solo de c√≥digo
2. MLflow simplifica el tracking de experimentos masivamente
3. DVC permite trabajar con archivos grandes sin saturar Git
4. DagsHub integra todas las herramientas en una plataforma


## üìö Referencias

1. MLflow Documentation. (2024). https://mlflow.org/docs/latest/index.html
2. DVC Documentation. (2024). https://dvc.org/doc
3. Scikit-learn User Guide. (2024). https://scikit-learn.org/stable/user_guide.html
4. DagsHub Documentation. (2024). https://dagshub.com/docs
5. Telco Customer Churn Dataset.

---

## üìù Notas de Entrega

### Entregables Incluidos
- ‚úÖ C√≥digo fuente completo (`src/`, `scripts/`)
- ‚úÖ Configuraciones de experimentos (`params_experiments/`)
- ‚úÖ Dataset procesado y versionado (DVC)
- ‚úÖ Modelos entrenados y versionados (DVC)
- ‚úÖ Reporte de experimentos (`reports/experiments_comparison.csv`)
- ‚úÖ Tracking de experimentos en DagsHub/MLflow
- ‚úÖ Documentaci√≥n completa (este README)

### Acceso al Proyecto
- **Repositorio:** https://dagshub.com/Nacho/Proyecto_Telco
- **Experimentos MLflow:** https://dagshub.com/Nacho/Proyecto_Telco.mlflow
- **Datos DVC:** https://dagshub.com/Nacho/Proyecto_Telco.dvc

### Instrucciones para Evaluaci√≥n
1. Clonar repositorio desde DagsHub
2. Ejecutar `dvc pull` para descargar datos
3. Revisar experimentos en pesta√±a "Experiments" de DagsHub
4. Ejecutar entrenamiento con `python src/train.py --params params.yaml`
5. Ver comparaci√≥n de experimentos en `reports/experiments_comparison.csv`

---

## üìß Contacto

Para consultas sobre este proyecto:
- **DagsHub:** https://dagshub.com/Nacho

---

**Proyecto desarrollado como parte del Trabajo Pr√°ctico Integrador de Laboratorio de Miner√≠a de Datos**

*Octubre 2025*