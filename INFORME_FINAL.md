# üìä Informe Final - TelcoVision

**Trabajo Pr√°ctico Integrador - Laboratorio de Miner√≠a de Datos**

---

## üìã Informaci√≥n del Proyecto

| Campo | Detalle |
|-------|---------|
| **Nombre del Proyecto** | TelcoVision - Sistema MLOps para Predicci√≥n de Churn |
| **Estudiantes** | Evelyn Solange Irusta, Ignacio Heck |
| **Instituci√≥n** | ISTEA |
| **Materia** | Laboratorio de Miner√≠a de Datos |
| **Fecha de Entrega** | Noviembre 2025 |
| **Repositorio GitHub** | https://github.com/Shaftyel/Proyecto_telco |
| **Repositorio DagsHub** | https://dagshub.com/Nacho/proyecto_telco |

---

## üéØ Resumen Ejecutivo

TelcoVision es un sistema completo de Machine Learning implementado con pr√°cticas MLOps profesionales para predecir la cancelaci√≥n de servicios (churn) en clientes de telecomunicaciones. El proyecto abarca desde la ingesta y preprocesamiento de datos hasta el deployment en producci√≥n, incluyendo versionado de datos/modelos, tracking de experimentos, CI/CD automatizado y m√∫ltiples opciones de despliegue.

### Resultados Clave

- ‚úÖ **Pipeline automatizado** de 3 stages con DVC
- ‚úÖ **6 experimentos** ejecutados con metodolog√≠a colaborativa
- ‚úÖ **Modelo ganador:** Random Forest Conservador (ROC-AUC: 72.53%, Recall: 64.65%)
- ‚úÖ **CI/CD automatizado** validando cada cambio
- ‚úÖ **4 opciones de deployment** documentadas y listas para producci√≥n
- ‚úÖ **Visualizaciones profesionales** (matriz de confusi√≥n, curva ROC, curva PR)

---

## üìä 1. Problema de Negocio

### Contexto

En la industria de telecomunicaciones, la retenci√≥n de clientes es cr√≠tica para la rentabilidad. Adquirir nuevos clientes es entre 5-25 veces m√°s costoso que retener los existentes. La predicci√≥n temprana de churn permite implementar estrategias de retenci√≥n proactivas.

### Objetivo

Desarrollar un sistema de predicci√≥n de churn que:
1. Identifique clientes en riesgo con **alta precisi√≥n** (recall > 60%)
2. Sea **reproducible y escalable** mediante MLOps
3. Permita **experimentaci√≥n r√°pida** de diferentes modelos
4. Est√© **listo para producci√≥n** con opciones de deployment

### M√©tricas de √âxito

- **Recall > 60%:** Detectar al menos 60% de casos de churn
- **ROC-AUC > 70%:** Capacidad discriminativa s√≥lida
- **Pipeline reproducible:** Cualquier experimento replicable
- **CI/CD funcional:** Validaci√≥n autom√°tica de cambios

---

## üìà 2. Datos y Preprocesamiento

### Dataset

- **Fuente:** Telco Customer Churn Dataset
- **Registros:** 10,000 clientes
- **Features originales:** 12 (9 categ√≥ricas, 3 num√©ricas)
- **Variable objetivo:** `churn` (binaria: 0 = activo, 1 = cancel√≥)
- **Distribuci√≥n de clases:**
  - No churn: 6,367 (63.67%)
  - Churn: 3,633 (36.33%)

### Pipeline de Preprocesamiento

**Stage: `data_prep`**

```python
# Transformaciones aplicadas:
1. Normalizaci√≥n de nombres de columnas
2. Conversi√≥n de tipos de datos
3. Imputaci√≥n de valores faltantes (mediana)
4. Eliminaci√≥n de identificadores
5. One-hot encoding (drop_first=True)
6. Estandarizaci√≥n (StandardScaler)
```

**Resultado:** 24 features procesadas

**Versionado:** `data/processed/telco_churn_processed.csv.dvc`

---

## ü§ñ 3. Experimentaci√≥n y Selecci√≥n de Modelo

### Metodolog√≠a

Se implement√≥ un **workflow colaborativo** con:
- Git branches por experimento (`feat-experimento-*`)
- Pull Requests para revisi√≥n
- Validaci√≥n autom√°tica con CI/CD
- Tracking en MLflow/DagsHub

### Experimentos Ejecutados

| # | Configuraci√≥n | Autor | Accuracy | Recall | ROC-AUC | Status |
|---|--------------|-------|----------|--------|---------|--------|
| 1 | RF 500 √°rboles | Nacho | 66.7% | 51.0% | 71.0% | ‚ùå Cerrado |
| 2 | RF Regularizado | Nacho | 66.6% | 62.6% | 72.0% | ‚ùå Cerrado (Subcampe√≥n) |
| 3 | RF Balanceado | Nacho | 67.2% | 56.8% | 71.6% | ‚ùå Cerrado |
| 4 | RF Alto Rendimiento | Solange | 67.1% | 42.9% | 70.2% | ‚ùå Cerrado |
| **5** | **RF Conservador** | **Solange** | **66.7%** | **64.7%** ü•á | **72.5%** ü•á | ‚úÖ **MERGED** |
| 6 | RF Equilibrado | Solange | 67.5% | 56.5% | 71.8% | ‚ùå Cerrado |

### Configuraci√≥n del Modelo Ganador

**Experimento 5: Random Forest Conservador**

```yaml
model:
  type: RandomForest
  parameters:
    n_estimators: 180
    max_depth: 14
    min_samples_split: 12
    min_samples_leaf: 6
    class_weight: balanced_subsample
    random_state: 42
```

### Justificaci√≥n de Selecci√≥n

El **Experimento 5** fue seleccionado como modelo ganador por:

1. **ü•á Mejor ROC-AUC (72.53%)**
   - Superior capacidad de discriminaci√≥n entre clases
   - Indica que el modelo ordena correctamente las probabilidades

2. **ü•á Mejor Recall (64.65%)**
   - Detecta 646 de cada 1000 clientes que har√°n churn
   - Cr√≠tico para el negocio: minimiza casos perdidos

3. **ü•á Mejor F1-Score (58.49%)**
   - Mejor balance entre precisi√≥n y recall
   - Demuestra consistencia del modelo

4. **üíº Impacto de Negocio**
   - En telecomunicaciones, detectar clientes en riesgo > accuracy general
   - Un falso positivo (ofrecer retenci√≥n innecesaria) tiene bajo costo
   - Un falso negativo (perder cliente) tiene alto costo

### Comparaci√≥n con Subcampe√≥n

| M√©trica | Exp 5 (Ganador) | Exp 2 (Subcampe√≥n) | Diferencia |
|---------|-----------------|--------------------|-----------| 
| ROC-AUC | 72.53% | 72.00% | +0.53% |
| Recall | 64.65% | 62.59% | +2.06% |
| F1-Score | 58.49% | 57.67% | +0.82% |

El Experimento 5 supera al subcampe√≥n en todas las m√©tricas cr√≠ticas para el negocio.

---

## üìä 4. Resultados del Modelo Final

### M√©tricas en Datos de Prueba (2000 muestras)

```
Accuracy:    66.65%
Precision:   53.41%
Recall:      64.65% ‚≠ê
F1-Score:    58.49%
ROC-AUC:     72.53% ‚≠ê
```

### Matriz de Confusi√≥n

```
                    Predicho
                 No Churn | Churn
         ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
Real     No Churn |  863  |  410
         Churn    |  257  |  470
```

**Interpretaci√≥n:**
- **True Positives (470):** Casos de churn correctamente identificados
- **False Negatives (257):** Casos de churn perdidos (35.35% de todos los churn)
- **False Positives (410):** Clientes sin riesgo marcados como churn
- **True Negatives (863):** Clientes activos correctamente identificados

### Curva ROC

**AUC: 0.7253**

La curva ROC muestra que el modelo tiene capacidad discriminativa s√≥lida, muy superior a un clasificador aleatorio (AUC = 0.50).

### Curva Precision-Recall

**Average Precision: 0.5773**

Dado el desbalance de clases, esta m√©trica es m√°s informativa que accuracy. El modelo mantiene precisi√≥n razonable incluso con recall alto.

### Reporte de Clasificaci√≥n

```
              precision    recall  f1-score   support

    No Churn       0.77      0.68      0.72      1273
       Churn       0.53      0.65      0.58       727

    accuracy                           0.67      2000
   macro avg       0.65      0.66      0.65      2000
weighted avg       0.68      0.67      0.67      2000
```

---

## üîÑ 5. Pipeline MLOps Implementado

### Arquitectura

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Raw Data   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
       ‚îÇ DVC tracked
       ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ data_prep   ‚îÇ ‚Üê src/data_prep.py
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
       ‚îÇ
       ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Processed   ‚îÇ
‚îÇ   Data      ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
       ‚îÇ
       ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   train     ‚îÇ ‚Üê src/train.py + MLflow
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
       ‚îÇ
       ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   Model +   ‚îÇ
‚îÇ  Metrics    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
       ‚îÇ
       ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  evaluate   ‚îÇ ‚Üê src/evaluate.py
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
       ‚îÇ
       ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   Plots +   ‚îÇ
‚îÇ  Reports    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Componentes del Sistema

#### 1. Versionado de Datos (DVC)

```bash
# Archivos versionados:
data/raw/telco_churn.csv.dvc
data/processed/telco_churn_processed.csv.dvc
models/model.joblib.dvc
```

**Beneficios:**
- Trazabilidad completa de cambios en datos
- Colaboraci√≥n sin duplicar archivos grandes
- Rollback a versiones anteriores

#### 2. Tracking de Experimentos (MLflow)

```python
# Cada experimento registra:
- Par√°metros: n_estimators, max_depth, etc.
- M√©tricas: accuracy, precision, recall, f1, roc_auc
- Artifacts: modelo .joblib, m√©tricas .json
- Tags: autor, versi√≥n, prop√≥sito
```

**Repositorio:** https://dagshub.com/Nacho/proyecto_telco.mlflow

#### 3. CI/CD (GitHub Actions)

**Workflow:** `.github/workflows/ci.yaml`

**Triggers:**
- Push a `main`, `dev`, `feat-*`
- Pull Requests a `main`

**Jobs ejecutados:**
1. Setup Python 3.9
2. Instalar dependencias
3. Ejecutar pipeline DVC completo
4. Validar m√©tricas (accuracy > 60%)
5. Subir artefactos
6. Tracking a MLflow

**Resultado:** Validaci√≥n autom√°tica de cada experimento

#### 4. Colaboraci√≥n (GitHub + DagsHub)

**GitHub:** https://github.com/Shaftyel/Proyecto_telco
- Control de versiones del c√≥digo
- Pull Requests y code review
- Issues y project management

**DagsHub:** https://dagshub.com/Nacho/proyecto_telco
- Experimentos MLflow
- Storage DVC
- Visualizaci√≥n de m√©tricas

---

## üöÄ 6. Estrategia de Despliegue en Producci√≥n

Se documentaron **4 opciones de deployment** en `GUIA_DESPLIEGUE.md`:

### Opci√≥n 1: API REST (FastAPI) ‚ö°

**Caracter√≠sticas:**
- API REST production-ready
- Documentaci√≥n autom√°tica (Swagger)
- Endpoints: `/predict`, `/predict_batch`, `/health`
- Validaci√≥n con Pydantic
- Performance: <100ms por predicci√≥n

**Casos de uso:**
- Integraci√≥n con sistemas existentes
- Aplicaciones m√≥viles/web
- Microservicios

**Deployment:**
- Servidor: systemd service
- Cloud: AWS Elastic Beanstalk, GCP Cloud Run, Azure App Service
- Containerizado: Docker + Kubernetes

### Opci√≥n 2: Dashboard Web (Streamlit) üé®

**Caracter√≠sticas:**
- Interface web interactiva
- Visualizaciones con Plotly
- Gauge de probabilidad de churn
- Recomendaciones autom√°ticas

**Casos de uso:**
- Demos para stakeholders
- Herramienta interna para analistas
- Prototipado r√°pido

**Deployment:**
- Streamlit Cloud (gratis)
- Servidor interno

### Opci√≥n 3: Procesamiento por Lotes üì¶

**Caracter√≠sticas:**
- Script para m√∫ltiples clientes
- Generaci√≥n de reportes CSV
- Ejecuci√≥n programada (cron)

**Casos de uso:**
- Scoring mensual de toda la base
- Reportes peri√≥dicos
- ETL pipelines

### Opci√≥n 4: Containerizaci√≥n (Docker) üê≥

**Caracter√≠sticas:**
- Dockerfile completo
- docker-compose con m√∫ltiples servicios
- Portabilidad total

**Casos de uso:**
- Deployment agn√≥stico de plataforma
- Entornos de desarrollo id√©nticos
- Escalamiento horizontal

### Recomendaci√≥n para Producci√≥n

**Arquitectura sugerida:**

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ         Load Balancer (Nginx)           ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
            ‚îÇ
            ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ    FastAPI Container (3 instancias)     ‚îÇ
‚îÇ    - Predicci√≥n en tiempo real          ‚îÇ
‚îÇ    - Health checks                       ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
            ‚îÇ
            ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ         PostgreSQL Database             ‚îÇ
‚îÇ    - Logging de predicciones            ‚îÇ
‚îÇ    - Audit trail                         ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ      Batch Job (Scheduled)              ‚îÇ
‚îÇ    - Scoring mensual completo           ‚îÇ
‚îÇ    - Re-entrenamiento autom√°tico        ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ    Monitoring (Prometheus + Grafana)    ‚îÇ
‚îÇ    - M√©tricas de performance            ‚îÇ
‚îÇ    - Data drift detection               ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Monitoreo Post-Deployment

**M√©tricas a trackear:**
1. **Performance del modelo:**
   - Accuracy, Precision, Recall en producci√≥n
   - Data drift (cambios en distribuci√≥n de datos)
   - Prediction drift (cambios en distribuci√≥n de predicciones)

2. **Performance del sistema:**
   - Latencia de respuesta (target: <100ms)
   - Throughput (requests/segundo)
   - Uso de recursos (CPU, memoria)
   - Tasa de errores

3. **M√©tricas de negocio:**
   - Tasa de churn real vs predicho
   - ROI de acciones preventivas
   - Costo de falsos positivos/negativos

### Re-entrenamiento

**Estrategia:**
- **Frecuencia:** Mensual
- **Trigger:** Detecci√≥n de data drift OR performance degradation
- **Pipeline:** Automatizado con DVC + GitHub Actions
- **Validaci√≥n:** A/B testing antes de reemplazar modelo actual

---

## üí° 7. Aprendizajes y Mejores Pr√°cticas

### T√©cnicos

#### Lo que funcion√≥ bien ‚úÖ

1. **DVC para versionado de datos**
   - Simplicidad: archivos `.dvc` peque√±os en Git
   - Eficiencia: solo se almacenan diferencias
   - Colaboraci√≥n: m√∫ltiples personas sin conflictos

2. **MLflow para tracking**
   - Comparaci√≥n visual de experimentos
   - Historial completo de runs
   - Artifacts versionados autom√°ticamente

3. **GitHub Actions para CI/CD**
   - Validaci√≥n autom√°tica de cada cambio
   - Prevenci√≥n de errores en main
   - Feedback r√°pido (< 5 minutos)

4. **Branches + PRs para experimentaci√≥n**
   - Experimentar sin romper main
   - Code review estructurado
   - Historial claro de decisiones

#### Desaf√≠os enfrentados ‚ö†Ô∏è

1. **Integraci√≥n DVC + GitHub**
   - Problema: Archivos grandes en Git
   - Soluci√≥n: Asegurar que `.dvc` files est√°n en .gitignore

2. **Encoding en Windows**
   - Problema: Emojis en scripts causaban errores
   - Soluci√≥n: Usar solo ASCII en c√≥digo cr√≠tico

3. **Feature importance en modelo**
   - Problema: RF no expon√≠a feature_importances_
   - Soluci√≥n: Generar placeholder o quitar del pipeline

### MLOps

#### Principios aplicados üìê

1. **Everything as Code**
   - Configuraci√≥n: `params.yaml`
   - Pipeline: `dvc.yaml`
   - CI/CD: `.github/workflows/ci.yaml`

2. **Reproducibilidad**
   - Random seeds fijos
   - Dependencias versionadas
   - Entornos aislados (conda)

3. **Automatizaci√≥n**
   - Pipeline completo con `dvc repro`
   - CI/CD sin intervenci√≥n manual
   - Tracking autom√°tico de experimentos

4. **Colaboraci√≥n**
   - Git workflow est√°ndar
   - Pull Requests para cambios
   - Documentaci√≥n actualizada

#### Lecciones aprendidas üéì

1. **Versionado de datos es tan importante como c√≥digo**
   - Los modelos dependen de los datos
   - Reproducibilidad requiere versionar ambos

2. **Documentaci√≥n temprana ahorra tiempo**
   - README claro facilita onboarding
   - Gu√≠as reducen preguntas repetitivas

3. **CI/CD previene errores costosos**
   - Validaci√≥n autom√°tica > revisi√≥n manual
   - Feedback r√°pido > debugging tard√≠o

4. **M√©tricas deben alinearse con negocio**
   - Accuracy != m√©trica correcta siempre
   - En churn, recall > precision

### Mejoras Futuras

#### Corto Plazo (1-2 semanas)
- [ ] Implementar SMOTE para balanceo de clases
- [ ] Probar XGBoost y LightGBM
- [ ] Agregar feature engineering (ratios, interacciones)
- [ ] Implementar API REST en staging

#### Mediano Plazo (1-2 meses)
- [ ] Hyperparameter tuning con Optuna
- [ ] Ensamble de modelos (voting, stacking)
- [ ] Dashboard de monitoreo con Grafana
- [ ] A/B testing en producci√≥n

#### Largo Plazo (3+ meses)
- [ ] Incorporar datos de tiempo real (streaming)
- [ ] Explainability con SHAP values
- [ ] Predicci√≥n de Customer Lifetime Value
- [ ] Recomendaciones personalizadas de retenci√≥n

---

## üìä 8. Impacto y Resultados

### M√©tricas del Proyecto

| Aspecto | M√©trica | Resultado |
|---------|---------|-----------|
| **Experimentaci√≥n** | N√∫mero de experimentos | 6 |
| **Colaboraci√≥n** | N√∫mero de colaboradores | 2 (Nacho + Solange) |
| **Automatizaci√≥n** | Pipeline stages | 3 (data_prep, train, evaluate) |
| **CI/CD** | Pull Requests validados | 6 |
| **Documentaci√≥n** | P√°ginas de docs | 5 archivos .md |
| **Deployment** | Opciones documentadas | 4 (API, Streamlit, Batch, Docker) |

### Impacto de Negocio Proyectado

**Escenario:** Empresa de telecomunicaciones con 100,000 clientes

**M√©tricas actuales (sin modelo):**
- Tasa de churn mensual: 3% (3,000 clientes/mes)
- Costo de adquisici√≥n por cliente: $500
- P√©rdida mensual: $1,500,000

**Con modelo implementado:**

Usando Recall = 64.65%:
- Clientes en riesgo detectados: 1,940 de 3,000
- Costo de retenci√≥n por cliente: $100
- Inversi√≥n en retenci√≥n: $194,000

Si logramos retener 40% de los contactados:
- Clientes retenidos: 776
- Ahorro en costo de re-adquisici√≥n: $388,000
- **ROI mensual: $194,000** (100% en primer mes)

**ROI anual proyectado: $2,328,000**

---

## ‚úÖ 9. Cumplimiento de Objetivos

### Objetivos Planteados vs Alcanzados

| Objetivo | Meta | Alcanzado | Status |
|----------|------|-----------|--------|
| Pipeline reproducible | DVC funcional | 3 stages automatizados | ‚úÖ |
| Tracking de experimentos | MLflow integrado | 6 experimentos tracked | ‚úÖ |
| CI/CD automatizado | GitHub Actions | Validaci√≥n en cada PR | ‚úÖ |
| Modelo con recall > 60% | 60%+ | 64.65% | ‚úÖ |
| Modelo con ROC-AUC > 70% | 70%+ | 72.53% | ‚úÖ |
| Documentaci√≥n completa | README + gu√≠as | 5 archivos .md | ‚úÖ |
| Opciones de deployment | Al menos 2 | 4 documentadas | ‚úÖ |
| Colaboraci√≥n remota | DagsHub funcional | GitHub + DagsHub | ‚úÖ |

**Resultado: 8/8 objetivos cumplidos** üéâ

---

## üìö 10. Referencias

### Documentaci√≥n del Proyecto
- **README.md** - Visi√≥n general completa
- **GUIA_COLABORADOR.md** - Onboarding para nuevos miembros
- **GUIA_DESPLIEGUE.md** - Opciones de deployment
- **COMPARACION_EXPERIMENTOS_FINAL.md** - An√°lisis detallado de experimentos

### Repositorios
- **GitHub:** https://github.com/Shaftyel/Proyecto_telco
- **DagsHub:** https://dagshub.com/Nacho/proyecto_telco
- **MLflow:** https://dagshub.com/Nacho/proyecto_telco.mlflow

### Tecnolog√≠as
- [MLflow Documentation](https://mlflow.org/docs/)
- [DVC Documentation](https://dvc.org/doc)
- [FastAPI Documentation](https://fastapi.tiangolo.com)
- [Scikit-learn User Guide](https://scikit-learn.org/stable/)

### Papers y Recursos
- MLOps: Continuous delivery and automation pipelines in ML (Google Cloud)
- Reproducibility in Machine Learning (Papers with Code)

---

## üë• 11. Equipo y Contribuciones

### Nacho
**Rol:** Project Owner / ML Engineer

**Contribuciones:**
- Setup inicial del proyecto (Git, DVC, MLflow)
- Pipeline de preprocesamiento (`data_prep.py`)
- Script de entrenamiento con tracking (`train.py`)
- Experimentos 1, 2, 3 (500 √°rboles, regularizado, balanceado)
- Configuraci√≥n CI/CD (GitHub Actions)
- Integraci√≥n con DagsHub

### Solange
**Rol:** Colaboradora / Data Scientist

**Contribuciones:**
- Experimentos 4, 5, 6 (alto rendimiento, conservador, equilibrado)
- Script de evaluaci√≥n avanzada (`evaluate.py`)
- Identificaci√≥n del modelo ganador
- Visualizaciones (matriz confusi√≥n, curvas ROC/PR)

### Trabajo Conjunto
- Documentaci√≥n completa (README, gu√≠as)
- An√°lisis comparativo de experimentos
- Estrategia de deployment
- Preparaci√≥n de entregables

---

## üéØ 12. Conclusiones

### Logros Principales

1. **Sistema MLOps Completo**
   - Pipeline reproducible de principio a fin
   - Versionado de datos, c√≥digo y modelos
   - CI/CD validando cada cambio

2. **Modelo Production-Ready**
   - Recall: 64.65% (detecta 2 de cada 3 casos de churn)
   - ROC-AUC: 72.53% (capacidad discriminativa s√≥lida)
   - 4 opciones de deployment documentadas

3. **Experimentaci√≥n Estructurada**
   - 6 experimentos con metodolog√≠a consistente
   - Tracking completo en MLflow
   - Selecci√≥n justificada del mejor modelo

4. **Documentaci√≥n Profesional**
   - 5 archivos markdown completos
   - Gu√≠as para colaboradores y deployment
   - README exhaustivo

### Valor Agregado del Proyecto

**T√©cnico:**
- Framework replicable para futuros proyectos ML
- Best practices de MLOps documentadas
- C√≥digo production-ready

**Acad√©mico:**
- Aplicaci√≥n pr√°ctica de conceptos de miner√≠a de datos
- Integraci√≥n de m√∫ltiples herramientas (DVC, MLflow, GitHub Actions)
- Experiencia en trabajo colaborativo

**Profesional:**
- Portfolio demostrable de habilidades MLOps
- Experiencia en ciclo completo de proyecto ML
- Documentaci√≥n nivel empresarial

### Reflexi√≥n Final

Este proyecto demuestra que implementar MLOps no es solo "una buena pr√°ctica" sino una **necesidad** para proyectos de ML serios. La inversi√≥n en versionado, tracking y automatizaci√≥n se paga r√°pidamente en:

1. **Tiempo ahorrado** en debugging y reproducci√≥n
2. **Calidad mejorada** con validaci√≥n autom√°tica
3. **Colaboraci√≥n facilitada** con workflow estructurado
4. **Confianza incrementada** en resultados reproducibles

El modelo final, con recall de 64.65%, representa un balance pr√°ctico entre detectar churn y evitar falsos positivos. En un contexto real de negocio, este modelo podr√≠a generar ROI significativo al permitir acciones proactivas de retenci√≥n.

---

## üìé Anexos

### A. Estructura Completa del Repositorio

Ver: `README.md` secci√≥n "Estructura del Proyecto"

### B. Comandos √ötiles

```bash
# Setup inicial
git clone https://github.com/Shaftyel/Proyecto_telco.git
conda create -n telcovision python=3.9 -y
conda activate telcovision
pip install -r requirements.txt

# Ejecutar pipeline
dvc repro

# Ver experimentos
mlflow ui

# Ejecutar API
uvicorn src.api:app --reload

# Ejecutar dashboard
streamlit run src/app_streamlit.py
```

### C. M√©tricas Detalladas de Todos los Experimentos

Ver: `COMPARACION_EXPERIMENTOS_FINAL.md`

### D. Gu√≠a de Deployment Paso a Paso

Ver: `GUIA_DESPLIEGUE.md`

---

<div align="center">

## üéì Trabajo Pr√°ctico Integrador Completado

**TelcoVision - Sistema MLOps para Predicci√≥n de Churn**

Evelyn Solange Irusta ‚Ä¢ Ignacio Heck

ISTEA - Laboratorio de Miner√≠a de Datos

Noviembre 2025

---

*"En MLOps, la reproducibilidad no es opcional - es fundamental"*

</div>
