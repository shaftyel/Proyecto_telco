# üèÜ Comparaci√≥n Final de Experimentos - Proyecto TelcoVision

## Resumen Ejecutivo

Se realizaron **6 experimentos** con diferentes configuraciones de Random Forest para optimizar la predicci√≥n de churn en telecomunicaciones. El **Experimento 5** fue seleccionado como modelo ganador.

---

## Tabla Comparativa Completa

| # | Experimento | Autor | Accuracy | Precision | Recall | F1 | ROC-AUC | Estado |
|---|-------------|-------|----------|-----------|--------|-----|---------|--------|
| 1 | RF 500 √°rboles | Nacho | 66.7% | 54.48% | 51.03% | 52.70% | 71.00% | ‚ùå Cerrado |
| 2 | RF Regularizado | Nacho | 66.6% | 53.47% | 62.59% | 57.67% | 72.00% | ‚ùå Cerrado (Subcampe√≥n) |
| 3 | RF Balanceado | Nacho | 67.15% | 54.63% | 56.81% | 55.70% | 71.60% | ‚ùå Cerrado |
| 4 | RF Alto Rendimiento | Solange | 67.05% | 56.12% | 42.92% | 48.64% | 70.23% | ‚ùå Cerrado |
| 5 | **RF Conservador** | Solange | 66.65% | 53.41% | **64.65%** | **58.49%** | **72.53%** | ‚úÖ **MERGED** |
| 6 | RF Equilibrado | Solange | **67.5%** | 55.17% | 56.53% | 55.84% | 71.77% | ‚ùå Cerrado |

---

## üèÜ Experimento Ganador: #5 - RF Conservador

### Configuraci√≥n:

```
model:
  type: RandomForest
  parameters:
    n_estimators: 180
    max_depth: 14
    min_samples_split: 12
    min_samples_leaf: 6
    class_weight: balanced_subsample
```

### M√©tricas:

- **Accuracy:** 66.65%
- **Precision:** 53.41%
- **Recall:** 64.65% ü•á
- **F1-Score:** 58.49% ü•á
- **ROC-AUC:** 72.53% ü•á

### Justificaci√≥n de Selecci√≥n:

1. **Mejor ROC-AUC (72.53%):** Superior capacidad de discriminaci√≥n entre clientes que har√°n/no har√°n churn
2. **Mejor Recall (64.65%):** Detecta el 65% de los clientes en riesgo de abandono
3. **Mejor F1-Score (58.49%):** Mejor balance entre precisi√≥n y recall
4. **Impacto de negocio:** En un dataset de 2000 clientes de prueba con ~700 casos de churn, este modelo detecta 453 casos vs 397 del segundo mejor

### Impacto en el Negocio:

Para telecomunicaciones, **detectar clientes en riesgo** es m√°s valioso que accuracy general:

- Un **falso positivo** (ofrecer retenci√≥n a quien no se ir√°) tiene bajo costo
- Un **falso negativo** (no detectar a quien se ir√°) significa perder el cliente

El Experimento 5 minimiza los falsos negativos con el recall m√°s alto.

---

## üìä An√°lisis por M√©trica

### Mejores por Categor√≠a:

- ü•á **Accuracy:** Exp 6 (67.5%)
- ü•á **Precision:** Exp 4 (56.12%)
- ü•á **Recall:** Exp 5 (64.65%) ‚≠ê
- ü•á **F1-Score:** Exp 5 (58.49%) ‚≠ê
- ü•á **ROC-AUC:** Exp 5 (72.53%) ‚≠ê

---

## üéØ Ranking Final

1. ü•á **Experimento 5** (Solange) - ROC-AUC: 72.53%
2. ü•à **Experimento 2** (Nacho) - ROC-AUC: 72.00%
3. ü•â **Experimento 6** (Solange) - Accuracy: 67.5%
4. **Experimento 3** (Nacho) - Accuracy: 67.15%
5. **Experimento 1** (Nacho) - Baseline s√≥lido
6. **Experimento 4** (Solange) - Recall bajo

---

## üî¨ Aprendizajes Clave

### Configuraciones exitosas:

- **Regularizaci√≥n moderada-alta** funcion√≥ mejor que modelos muy complejos
- **class_weight balanceado** fue crucial para el recall
- **Profundidad limitada** (14-20) evit√≥ overfitting

### Configuraciones menos efectivas:

- Muchos √°rboles sin regularizaci√≥n ‚Üí bajo recall
- Profundidad ilimitada ‚Üí no mejor√≥ significativamente

---

## üìà Proceso MLOps Utilizado

### Herramientas:

- **Git:** Control de versiones del c√≥digo
- **GitHub Actions:** CI/CD autom√°tico para validar cada experimento
- **DVC:** Versionado de datos y pipeline reproducible
- **MLflow:** Tracking de experimentos y m√©tricas
- **DagsHub:** Plataforma colaborativa para MLOps

### Workflow Implementado:

1. Cada experimento en rama `feat-*` separada
2. Pull Request con descripci√≥n detallada de hip√≥tesis y configuraci√≥n
3. Validaci√≥n autom√°tica mediante CI/CD (GitHub Actions)
4. Revisi√≥n colaborativa de m√©tricas
5. Merge del mejor experimento a `main`
6. Cierre documentado de experimentos no seleccionados

### Validaci√≥n CI/CD:

Cada PR ejecut√≥ autom√°ticamente:
- ‚úÖ Instalaci√≥n de dependencias
- ‚úÖ Ejecuci√≥n del pipeline DVC
- ‚úÖ Validaci√≥n de accuracy m√≠nima (>60%)
- ‚úÖ Registro de m√©tricas y artefactos
- ‚úÖ Tracking en MLflow/DagsHub

---

## üìä Detalles de Todos los Experimentos

### Experimento 1: RF 500 √°rboles (Nacho)

**Configuraci√≥n:**
```
n_estimators: 500
max_depth: 20
min_samples_split: 5
min_samples_leaf: 2
class_weight: balanced_subsample
```

**Resultados:**
- Accuracy: 66.7%
- Recall: 51.03%
- ROC-AUC: 71.00%

**An√°lisis:** Baseline s√≥lido pero recall insuficiente para negocio.

---

### Experimento 2: RF Regularizado (Nacho) ü•à

**Configuraci√≥n:**
```
n_estimators: 200
max_depth: 15
min_samples_split: 10
min_samples_leaf: 5
class_weight: balanced_subsample
```

**Resultados:**
- Accuracy: 66.6%
- Recall: 62.59%
- ROC-AUC: 72.00%

**An√°lisis:** Subcampe√≥n. Excelente balance, podr√≠a ser alternativa en producci√≥n.

---

### Experimento 3: RF Balanceado (Nacho)

**Configuraci√≥n:**
```
n_estimators: 250
max_depth: 18
min_samples_split: 4
min_samples_leaf: 3
class_weight: balanced
```

**Resultados:**
- Accuracy: 67.15%
- Recall: 56.81%
- ROC-AUC: 71.60%

**An√°lisis:** Buena accuracy pero recall medio.

---

### Experimento 4: RF Alto Rendimiento (Solange)

**Configuraci√≥n:**
```
n_estimators: 450
max_depth: 22
min_samples_split: 3
min_samples_leaf: 1
class_weight: balanced
```

**Resultados:**
- Accuracy: 67.05%
- Recall: 42.92% (el m√°s bajo)
- ROC-AUC: 70.23%

**An√°lisis:** Muchos √°rboles sin suficiente regularizaci√≥n result√≥ en bajo recall.

---

### Experimento 5: RF Conservador (Solange) üèÜ

**Configuraci√≥n:**
```
n_estimators: 180
max_depth: 14
min_samples_split: 12
min_samples_leaf: 6
class_weight: balanced_subsample
```

**Resultados:**
- Accuracy: 66.65%
- Recall: 64.65% ü•á
- ROC-AUC: 72.53% ü•á

**An√°lisis:** GANADOR. Alta regularizaci√≥n + balance de clases = mejor detecci√≥n de churn.

---

### Experimento 6: RF Equilibrado (Solange) ü•â

**Configuraci√≥n:**
```
n_estimators: 320
max_depth: 20
min_samples_split: 5
min_samples_leaf: 3
class_weight: balanced
```

**Resultados:**
- Accuracy: 67.5% ü•á (la m√°s alta)
- Recall: 56.53%
- ROC-AUC: 71.77%

**An√°lisis:** Mejor accuracy pero recall insuficiente para el objetivo de negocio.

---

## üë• Colaboradores

### Nacho
- Rol: Owner del proyecto
- Contribuci√≥n: 3 experimentos (1, 2, 3)
- Destacado: Experimento 2 (subcampe√≥n)

### Solange
- Rol: Colaboradora
- Contribuci√≥n: 3 experimentos (4, 5, 6)
- Destacado: Experimento 5 (ganador) üèÜ

---

## üìÖ Timeline del Proyecto

- **Etapa 1-4:** Setup inicial, pipeline base, experimentos iniciales
- **Etapa 5:** Implementaci√≥n CI/CD con GitHub Actions
- **Etapa 6:** Iteraci√≥n colaborativa
  - Primera iteraci√≥n: Experimentos 1-3 (Nacho)
  - Segunda iteraci√≥n: Experimentos 4-6 (Solange)
  - An√°lisis comparativo y selecci√≥n
  - Merge a main: Experimento 5
- **Estado actual:** Modelo en main listo para producci√≥n

---

## üöÄ Pr√≥ximos Pasos Recomendados

### Inmediato:
1. ‚úÖ Modelo en main con configuraci√≥n del Exp 5
2. ‚è≠Ô∏è Despliegue a entorno de staging
3. ‚è≠Ô∏è Pruebas con datos recientes

### Corto plazo:
- Implementar monitoreo de m√©tricas en producci√≥n
- A/B testing entre Exp 5 y Exp 2
- Dashboard de visualizaci√≥n de predicciones

### Mediano plazo:
- Re-entrenamiento autom√°tico mensual
- Incorporar nuevas features
- An√°lisis de drift de datos

---

## üìö Documentaci√≥n Adicional

- **README.md:** Visi√≥n general del proyecto
- **GUIA_COLABORADOR.md:** Gu√≠a para nuevos colaboradores
- **dvc.yaml:** Definici√≥n del pipeline
- **params.yaml:** Configuraci√≥n del modelo ganador
- **.github/workflows/ci.yaml:** Configuraci√≥n CI/CD

---

## üéì Aprendizajes para el Equipo

### T√©cnicos:
- La regularizaci√≥n es m√°s importante que la complejidad del modelo
- El balance de clases (class_weight) es crucial en problemas desbalanceados
- M√°s √°rboles no siempre es mejor si no hay regularizaci√≥n adecuada

### MLOps:
- CI/CD automatizado acelera la experimentaci√≥n
- Git branches + PRs facilitan la colaboraci√≥n
- Documentaci√≥n clara es esencial para reproducibilidad

### Negocio:
- Las m√©tricas deben alinearse con objetivos de negocio
- En churn, recall > accuracy
- La interpretaci√≥n de resultados es tan importante como los n√∫meros

---

## ‚úÖ Conclusi√≥n

El proyecto TelcoVision complet√≥ exitosamente la **Etapa 6 de Iteraci√≥n Colaborativa**, generando 6 experimentos validados mediante CI/CD y seleccionando el modelo con mejor desempe√±o para predicci√≥n de churn.

El **Experimento 5** demostr√≥ que una configuraci√≥n conservadora con alta regularizaci√≥n y balance de clases logra los mejores resultados para detectar clientes en riesgo de abandono.

---

**Proyecto:** TelcoVision  
**Versi√≥n del Modelo:** Experimento 5 - RF Conservador  
**Fecha de Selecci√≥n:** Noviembre 2025
